{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import h5py \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "sys.path.insert(0, \"../examples\")\n",
    "sys.path.insert(0, \"data/components/\")\n",
    "from QMmodel import GNN_QM\n",
    "from MDmodel import GNN_MD\n",
    "from data.components.transformQM import GNNTransformQM\n",
    "from data.components.transformMD import GNNTransformMD\n",
    "from data.processing.inference_QM import main\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation H5 file from a ligand pdbid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to run inference on a new structure from PDB. It is either possible to provide a already downloaded fileName or to just give the pdbid and it will be downloaded automatically. (If you run the script directly in the terminal just give the keywords in the promt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  pdbid = \"vww\"\n",
    "  fileName = None\n",
    "  datasetOutName = 'inference_for_qm.hdf5'\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading vww.sdf\n"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Ionization potential and Hardness by our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the created h5 file and store the elements and coordinates in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmh5_file = \"inference_for_qm.hdf5\"\n",
    "qm_H5File = h5py.File(qmh5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"x\", \"y\", \"z\", \"element\"]\n",
    "atoms = pd.DataFrame(columns = column_names)\n",
    "\n",
    "prop = qm_H5File[\"vww\"][\"atom_properties\"][\"atom_properties_values\"]\n",
    "atoms[\"x\"] = prop[:,0].astype(np.float32)\n",
    "atoms[\"y\"] = prop[:,1].astype(np.float32)\n",
    "atoms[\"z\"] = prop[:,2].astype(np.float32)\n",
    "        \n",
    "atoms[\"element\"] = np.array([element for element in qm_H5File['vww']['atom_properties']['atoms_names'][:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = {\n",
    "    \"atoms\" : atoms,\n",
    "    \"labels\": 0,\n",
    "    \"bonds\": None, \n",
    "    \"id\": \"vww\"\n",
    "}\n",
    "\n",
    "transform = GNNTransformQM()\n",
    "data_item = transform(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run inference using cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN_QM(\n",
       "  (lin0): Linear(in_features=25, out_features=64, bias=True)\n",
       "  (conv): NNConv(64, 64, aggr=mean, nn=Sequential(\n",
       "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=4096, bias=True)\n",
       "  ))\n",
       "  (gru): GRU(64, 64)\n",
       "  (set2set): Set2Set(64, 128)\n",
       "  (lin1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (lin2): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GNN_QM(data_item.num_features, 64)\n",
    "cpt = torch.load(\"../examples/logs/QM_latest/best_weights_rep0.pt\", map_location=torch.device('cpu'))[\"model_state_dict\"]\n",
    "model.load_state_dict(cpt)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with the model\n",
    "y_hat = model(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0480, -0.0375], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating H5 file for a protein-ligand complex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the ligand case we download a pdb file, convert it to amber format and store it in an h5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.processing.pdb_to_h5 import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdh5_file = \"inference_for_md.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  pdbid = \"11GS\"\n",
    "  fileName = None\n",
    "  mapPath = \"data/processing/Maps/\"\n",
    "  mask = \"!@H=\" # no Hydrogens, see https://amberhub.chpc.utah.edu/atom-mask-selection-syntax/\n",
    "  datasetOutName = mdh5_file\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11GS/11GS.pdb was created. Please always use this file for inspection because the coordinates might get translated during amber file generation and thus might vary from the input pdb file.\n",
      "The following trajectory was created: pytraj.TrajectoryIterator, 1 frames: \n",
      "Size: 0.000146 (GB)\n",
      "<Topology: 6534 atoms, 416 residues, 2 mols, non-PBC>\n",
      "           \n",
      "molecule begin atom index [0, 1631, 3262] [1631, 1631]\n"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of adaptability by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_H5File = h5py.File(mdh5_file)\n",
    "\n",
    "column_names = [\"x\", \"y\", \"z\", \"element\"]\n",
    "atoms_protein = pd.DataFrame(columns = column_names)\n",
    "cutoff = md_H5File[\"11GS\"][\"molecules_begin_atom_index\"][:][-1] # cutoff defines protein atoms\n",
    "\n",
    "atoms_protein[\"x\"] = md_H5File[\"11GS\"][\"atoms_coordinates_ref\"][:][:cutoff, 0]\n",
    "atoms_protein[\"y\"] = md_H5File[\"11GS\"][\"atoms_coordinates_ref\"][:][:cutoff, 1]\n",
    "atoms_protein[\"z\"] = md_H5File[\"11GS\"][\"atoms_coordinates_ref\"][:][:cutoff, 2]\n",
    "\n",
    "atoms_protein[\"element\"] = md_H5File[\"11GS\"][\"atoms_element\"][:][:cutoff]  \n",
    "\n",
    "item = {}\n",
    "item[\"scores\"] = 0\n",
    "item[\"id\"] = \"11GS\"\n",
    "item[\"atoms_protein\"] = atoms_protein\n",
    "\n",
    "transform = GNNTransformMD()\n",
    "data_item = transform(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 1631, 3262])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " md_H5File[\"11GS\"][\"molecules_begin_atom_index\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN_MD(\n",
       "  (conv1): GCNConv(11, 64)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): GCNConv(64, 128)\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): GCNConv(128, 256)\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): GCNConv(256, 256)\n",
       "  (bn4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): GCNConv(256, 512)\n",
       "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "model = GNN_MD(data_item.num_features, 64)\n",
    "\n",
    "cpt = torch.load(\"../examples/logs/MD_latest/best_weights_rep0.pt\", map_location=torch.device('cpu'))[\"model_state_dict\"]\n",
    "\n",
    "model.load_state_dict(cpt)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3262])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data_item).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.6908, 5.0948, 4.0362,  ..., 1.4816, 1.5267, 1.6330],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Adaptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18efd6c025a040cbb8f416c93b53f759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nglview as nv\n",
    "import pytraj as pt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_opacity_to_spheres(num_spheres, opacity):\n",
    "    for i in range(num_spheres):\n",
    "        view.update_representation(component=view.n_components-i, opacity=opacity)\n",
    "              \n",
    "def show_ada_spheres(indices, prediction, color, radiusFactor):\n",
    "    for i in range(len(indices)):\n",
    "        pred_mask = '@'+str(indices[i]+1)\n",
    "        sh_value = prediction[indices[i]]\n",
    "        x,y,z = traj[pred_mask].xyz[:,:,:][0][0]\n",
    "        view.shape.add_sphere([x, y, z], color, prediction[indices[i]]/radiusFactor)\n",
    "\n",
    "def get_entries(struct, f):\n",
    "    atoms_coordinates_ref = f.get(struct+'/'+'trajectory_coordinates')[0]\n",
    "    atoms_element = f.get(struct+'/'+'atoms_element') \n",
    "    atoms_ada = f.get(struct+'/'+'atoms_feature_adaptability')\n",
    "    return atoms_coordinates_ref, atoms_element\n",
    "\n",
    "def get_entries_ada(struct, f):\n",
    "    atoms_coordinates_ref = f.get(struct+'/'+'atoms_coordinates_ref')\n",
    "    atoms_element = f.get(struct+'/'+'atoms_element') \n",
    "    atoms_ada = f.get(struct+'/'+'atoms_feature_adaptability')\n",
    "    return atoms_coordinates_ref, atoms_element, atoms_ada\n",
    "\n",
    "##\n",
    "## Not needed\n",
    "##\n",
    "        \n",
    "def show_ada_r_spheres_color_conversion(indices, ada_type, color, radiusFactor, index_conversion):\n",
    "    for i in indices:\n",
    "        pred_mask = '@'+str(i+1)\n",
    "        sh_value = prediction[ada_type][index_conversion[i]]\n",
    "        x,y,z = traj[pred_mask].xyz[:,:,:][0][0]\n",
    "        view.shape.add_sphere([x, y, z], color, prediction[sh_type][index_conversion[i]]/radiusFactor)\n",
    "        \n",
    "def get_index_conversion(atoms_element, atoms_coordinates_ref):\n",
    "    index_conversion = {}\n",
    "    noh_indices = np.where(atoms_element[:]!=1)[0] # change if not hydrogen\n",
    "    #h_indices = np.where(atoms_element[:]=1)[0]\n",
    "    equivalent_noh_index = 0\n",
    "    for all_atom_index in range(np.shape(atoms_coordinates_ref)[0]):\n",
    "        if all_atom_index in noh_indices:\n",
    "            index_conversion[equivalent_noh_index]=all_atom_index\n",
    "            equivalent_noh_index +=1\n",
    "    return index_conversion\n",
    "\n",
    "def get_values_from_atomIndices(prediction, indices, ada_type, index_conversion):\n",
    "    values = []\n",
    "    for index in indices:\n",
    "        values.append(prediction[ada_type][index_conversion[index]])\n",
    "    return values\n",
    "\n",
    "def convert_indices(indices, index_conversion):\n",
    "    values = []\n",
    "    for index in indices:\n",
    "        values.append(index_conversion[index])\n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the h5 file with hydrogens and the h5 file with the hydrogens stripped (noh) after processing so that we assign the correct atom indices for the pdb file that we want to visualize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ada = h5py.File('../data/MD/h5_files/tiny_md.hdf5', 'r')\n",
    "f_ada_noh = h5py.File(mdh5_file, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6600, 3)\n",
      "<HDF5 dataset \"atoms_coordinates_ref\": shape (3262, 3), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(f_ada['11GS']['trajectory_coordinates'][0]))\n",
    "print(f_ada_noh['11GS']['atoms_coordinates_ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = '11GS'\n",
    "atoms_coordinates_ref, atoms_element = get_entries(struct, f_ada)\n",
    "atoms_coordinates_ref_noH, atoms_element_noH, feature_ada_noh = get_entries_ada(struct, f_ada_noh)\n",
    "index_conversion = get_index_conversion(atoms_element, atoms_coordinates_ref)\n",
    "inverse_index_conversion= {value:key for key,value in index_conversion.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the MISATO colors\n",
    "cm = nv.color.ColormakerRegistry\n",
    "cm.add_scheme_func('dgreenC','''\n",
    " this.atomColor = function (atom) {\n",
    "     if (atom.element == \"C\") {\n",
    "       return 0x60a854 // C\n",
    "     } else if (atom.element == \"H\") {\n",
    "       return 0xecf0f1\n",
    "     } else if (atom.element == \"S\") {\n",
    "       return 0xf1c40f\n",
    "     } else if (atom.element == \"N\") {\n",
    "       return 0x2980b9\n",
    "     } else if (atom.element == \"O\") {\n",
    "       return 0xFF0D0D\n",
    "     }\n",
    " }\n",
    "''')\n",
    "cm.add_scheme_func('lgreenC','''\n",
    " this.atomColor = function (atom) {\n",
    "     if (atom.element == \"C\") {\n",
    "       return 0x89e876 // C\n",
    "     } else if (atom.element == \"H\") {\n",
    "       return 0xecf0f1\n",
    "     } else if (atom.element == \"S\") {\n",
    "       return 0xf1c40f\n",
    "     } else if (atom.element == \"N\") {\n",
    "       return 0x2980b9\n",
    "     } else if (atom.element == \"O\") {\n",
    "       return 0xFF0D0D\n",
    "     }\n",
    " }\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(model(data_item).detach().numpy(), columns = ['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['atoms_coordinates_ref', 'atoms_element', 'atoms_number', 'atoms_residue', 'atoms_type', 'molecules_begin_atom_index']>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_ada_noh['11GS'].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(model(data_item).detach().numpy(), columns = ['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.251047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.606583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.346603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.720964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.035377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>2.260487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>2.674389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>1.613312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>1.525985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>1.951239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3262 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction\n",
       "0       4.251047\n",
       "1       4.606583\n",
       "2       4.346603\n",
       "3       3.720964\n",
       "4       4.035377\n",
       "...          ...\n",
       "3257    2.260487\n",
       "3258    2.674389\n",
       "3259    1.613312\n",
       "3260    1.525985\n",
       "3261    1.951239\n",
       "\n",
       "[3262 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"atoms_coordinates_ref\": shape (3262, 3), type \"<f8\">"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_H5File['11GS']['atoms_coordinates_ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = '11GS'\n",
    "traj = pt.load(struct+'/'+struct+'.pdb')\n",
    "view = nv.show_pytraj(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c23930a4424121a37ed6f984ffc6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check from here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "residue_indices1 = list(traj.top.atom_indices(':27@C=,N=,O=,S='))\n",
    "residue_indices2 = list(traj.top.atom_indices(':58@C=,N=,O=,S='))\n",
    "residue_indices3 = list(traj.top.atom_indices(':107@C=,N=,O=,S='))\n",
    "residue_indices4 = list(traj.top.atom_indices(':100@C=,N=,O=,S='))\n",
    "residue_indices = residue_indices1+residue_indices2+residue_indices3+residue_indices4\n",
    "converted_indices = convert_indices(residue_indices, inverse_index_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ada_spheres(residue_indices, prediction['prediction'], (0,1,0), 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.render_image(trim=True, factor=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_opacity_to_spheres(view.n_components-1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.render_image(trim=True, factor=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.download_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sh_r_spheres_color_conversion(residue_indices, 'target', yellow, 2.5, inverse_index_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a740140079018068b3444b6d89694224b6cb3b34d8392a5487b58edeeeafee1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
